{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Логистическая регрессия, Регуляризация, Наивный Байес, K-ближайших соседей, Кросс-валидация и Подбор гиперпараметров\n",
    "  <hr>\n",
    "\n",
    "  ```\n",
    "  План лабораторной работы\n",
    "\n",
    "  1. Логистическая регрессия\n",
    "  2. Данные для задачи классификации (Data for Classification Task)\n",
    "  3. Работа с несбалансированными данными (Dealing with data imbalance)\n",
    "  4. Метрики оценки задачи классификации (Classification task evaluation metrics)\n",
    "  5. Регуляризация: Lasso и Ridge\n",
    "  6. Наивный Байес\n",
    "  7. K-ближайших соседей (KNN)\n",
    "  8. Кросс-валидация\n",
    "  9. Подбор гиперпараметров\n",
    "  ```\n",
    "\n",
    "  <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Логистическая регрессия\n",
    "\n",
    " Логистическая регрессия - это статистическая модель, используемая для задач бинарной (и мультиклассовой) классификации.\n",
    "\n",
    " Она оценивает вероятность принадлежности к определенному классу с помощью логистической (сигмоидной) функции.\n",
    "\n",
    "\n",
    "\n",
    " $$\\hat p(x) = \\frac{e^{\\beta_0 + \\beta_1 x}}{1+e^{\\beta_0 + \\beta_1 x}}$$\n",
    "\n",
    "\n",
    "\n",
    " <br>\n",
    "\n",
    " Функция потерь (Log Loss) используется для оценки производительности модели. Она штрафует модели за неправильные предсказания, особенно когда модель уверена в неправильном ответе.\n",
    "\n",
    " $$L(\\hat{p}(x_i), y_i) = -y_i * \\log (\\hat{p}(x_i)) - (1 - y_i) * \\log (1 -\\hat{p}(x_i))$$\n",
    "\n",
    "\n",
    "\n",
    " <br>\n",
    "\n",
    " Это можно переписать как:\n",
    "\n",
    " $$L(\\hat{p}(x_i), y_i) = \\left\\{\\begin{matrix}\n",
    "\n",
    " \\ - log (\\hat{p}(x_i)), & y_i=1\\\\\n",
    "\n",
    " \\ - log (1 -\\hat{p}(x_i)), & y_i=0\n",
    "\n",
    " \\end{matrix}\\right.$$\n",
    "\n",
    "\n",
    "\n",
    " <br>\n",
    "\n",
    " Для получения конечного предсказания (0 или 1) используется порог (threshold), обычно 0.5.\n",
    "\n",
    " $$\\hat y = \\left\\{\\begin{matrix}\n",
    "\n",
    " 1 && \\hat p(x) > threshold\\\\\n",
    "\n",
    " 0 && otherwise\n",
    "\n",
    " \\end{matrix}\\right.$$\n",
    "\n",
    "\n",
    "\n",
    " 1. Как выбрать порог (threshold)? Это важный вопрос, зависящий от баланса между точностью (precision) и полнотой (recall) для конкретной задачи.\n",
    "\n",
    "    Подробнее: [User Guide: Adjusting the prediction threshold](https://scikit-learn.org/stable/modules/calibration.html#adjusting-the-prediction-threshold)\n",
    "\n",
    "\n",
    "\n",
    " <br>\n",
    "\n",
    " Давайте посмотрим, как форма $\\hat p(x)$ зависит от её параметров:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1.1 Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1.2 Построение сигмоидальной функции\n",
    "\n",
    " Сигмоида - это S-образная кривая, которая отображает любое действительное число в значение от 0 до 1.\n",
    "\n",
    " Параметр b0 (смещение) сдвигает кривую вдоль оси x, а b1 (коэффициент при x) определяет крутизну кривой.\n",
    "\n",
    " Подробнее о сигмоиде: [Wikipedia: Sigmoid function](https://en.wikipedia.org/wiki/Sigmoid_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-10, 10, 0.01)\n",
    "\n",
    "\n",
    "def plot(b0, b1):\n",
    "    p = np.exp(b0 + b1 * x) / (1 + np.exp(b0 + b1 * x))\n",
    "    label = \"b0 = {}, b1 = {}\".format(b0, b1)\n",
    "    plt.plot(x, p, label=label)\n",
    "\n",
    "\n",
    "plot(0, 1)\n",
    "plot(0, 2)\n",
    "plot(0, 3)\n",
    "plot(5, 1)\n",
    "plt.legend()\n",
    "plt.title(\"Сигмоидальная функция\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Что контролируют параметры b0, b1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1.3 Построение функции потерь\n",
    "\n",
    " График показывает, как велика потеря (loss) в зависимости от предсказанной вероятности $\\hat p(x)$ для истинных меток y=1 и y=0.\n",
    "\n",
    " Обратите внимание, что потеря стремится к бесконечности, когда модель ошибается с высокой уверенностью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0.001, 1, 0.001)\n",
    "y1 = -np.log(x)\n",
    "y0 = -np.log(1 - x)\n",
    "\n",
    "plt.plot(x, y1, label=\"если y = 1\")\n",
    "plt.plot(x, y0, label=\"если y = 0\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " В чём преимущества использования логарифмов в функции потерь? <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Данные для задачи классификации\n",
    "\n",
    " В задачах классификации целевая переменная (y) является категориальной (например, 'здоров', 'болен'), в то время как в задачах регрессии она непрерывна (например, цена дома).\n",
    "\n",
    " Проведём анализ того, какие типы людей, скорее всего, выжили.\n",
    "\n",
    " В частности, мы попросим вас применить инструменты машинного обучения для предсказания того, какие пассажиры выжили в трагедии Титаника."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.1 Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv(\"titanic.csv\")\n",
    "titanic_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.2 Разведочный анализ данных (EDA)\n",
    "\n",
    "\n",
    "\n",
    " Подход к анализу наборов данных для суммирования их основных характеристик, часто с использованием графической статистики и других методов визуализации данных (например, matplotlib, plot распределения ..)<br>\n",
    "\n",
    " Сегодня мы попробуем инструмент под названием [ydata profiling](https://github.com/ydataai/ydata-profiling  ). \n",
    " **Примечание:** Всё, что делает pandas profilling, можно легко достичь с помощью pandas, matplotlib и numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "## Создать отчет о профиле данных\n",
    "profile = ProfileReport(\n",
    "    titanic_df, title=\"Отчет о профиле\"\n",
    ").to_notebook_iframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.3 Предварительная обработка данных\n",
    "\n",
    " 1. Как бороться с пропущенными значениями? Используются стратегии импутации (mean, median, mode, константа, модели).\n",
    "\n",
    "    Подробнее: [User Guide: Imputation](https://scikit-learn.org/stable/modules/impute.html)\n",
    "\n",
    " 1. Как бороться с категориальными данными? Применяются методы кодирования (One-Hot, Label, Ordinal и др.).\n",
    "\n",
    "    Подробнее: [User Guide: Encoding categorical features](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features)\n",
    "\n",
    " 1. Нужно ли масштабирование данных? Для логистической регрессии масштабирование может улучшить сходимость и устойчивость.\n",
    "\n",
    "    Подробнее: [User Guide: Scaling features](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaling)\n",
    "\n",
    "\n",
    "\n",
    " **ЗАДАНИЕ:**\n",
    "\n",
    " 1. Разделить данные на обучающую и тестовую выборки\n",
    "\n",
    " 2. Заполнить пропущенные значения\n",
    "\n",
    " 3. Использовать MinMaxScaler для масштабирования признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Выбрать признаки\n",
    "titanic_df.drop([\"name\"], axis=1, inplace=True)\n",
    "\n",
    "# TODO: Разделить данные на обучающую и тестовую выборки\n",
    "\n",
    "\n",
    "# TODO: Заполнить пропущенные значения\n",
    "\n",
    "\n",
    "# one-hot-encode категориальных признаков\n",
    "def ohe_new_features(df, features_name, encoder):\n",
    "    new_feats = encoder.transform(df[features_name])\n",
    "    # Создаем имена для новых столбцов\n",
    "    new_columns = [\n",
    "        f\"{features_name[0]}_{i}\" for i in range(new_feats.shape[1])\n",
    "    ]\n",
    "    new_cols = pd.DataFrame(new_feats, columns=new_columns, dtype=int)\n",
    "    new_df = pd.concat([df.reset_index(drop=True), new_cols], axis=1)\n",
    "    new_df.drop(features_name, axis=1, inplace=True)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "f_names = [\"sex\", \"embarked\"]\n",
    "encoder.fit(x_train[f_names])\n",
    "x_train = ohe_new_features(x_train, f_names, encoder)\n",
    "x_test = ohe_new_features(x_test, f_names, encoder)\n",
    "\n",
    "# TODO: масштабирование признаков с использованием MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.4 Построение, обучение и тестирование модели\n",
    "\n",
    "\n",
    "\n",
    " Теперь мы готовы увидеть логистическую регрессию на практике.\n",
    "\n",
    " Подробнее о логистической регрессии в scikit-learn: [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "\n",
    "\n",
    " ### Задание.\n",
    "\n",
    " 1. Обучить логистическую регрессию\n",
    "\n",
    " 1. Вывести метрики точности (Accuracy), полноты (Precision) и F-меры (Recall) на тестовом наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# TODO: обучить логистическую регрессию\n",
    "clf = None\n",
    "y_test_pred = None\n",
    "\n",
    "# TODO: вычислить метрики\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###  2.5 Интерпретация результатов предсказания и измерение производительности модели\n",
    "\n",
    "\n",
    "\n",
    " 1. изучение коэффициентов логистической регрессии\n",
    "\n",
    " 2. порог предсказания\n",
    "\n",
    "\n",
    "\n",
    " ### Задание :\n",
    "\n",
    " 1. Вычислить значения точности (Accuracy), полноты (Precision) и F-меры (Recall) для каждого из заданных пороговых значений и построить их графики.\n",
    "\n",
    " Подробнее о метриках можно почитать [здесь](https://scikit-learn.org/stable/modules/model_evaluation.html#from-binary-to-multiclass-and-multilabel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Коэффициенты логистической регрессии\n",
    "print(\"----Коэффициенты логистической регрессии----\")\n",
    "print(*[a for a in zip(list(x_train.columns), clf.coef_[0])], sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: вычислить метрики для каждого порога выше и построить результат, как показано ниже.\n",
    "thresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "pred_proba = clf.predict_proba(x_test)\n",
    "\n",
    "results = [[],[],[]]\n",
    "for i in thresholds:\n",
    "    #TODO: Вычислить accuracy_score, precision_score & recall_score\n",
    "\n",
    "plt.plot(thresholds, results[0], label = 'accuracy')\n",
    "plt.plot(thresholds, results[1], label = 'precision')\n",
    "plt.plot(thresholds, results[2], label = 'recall')\n",
    "plt.title('Выбор порога')\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('score')\n",
    "plt.legend()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Матрица ошибок (Confusion matrix)\n",
    "\n",
    " Матрица ошибок предоставляет подробную информацию о производительности классификатора, показывая, какие классы и как часто путаются.\n",
    "\n",
    " Подробнее: [User Guide: Confusion matrix](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix)\n",
    "\n",
    " <table><tr><td>\n",
    "\n",
    " <img align='center' src='https://static.packt-cdn.com/products/9781838555078/graphics/C13314_06_05.jpg  ' style='width: 350px;'>\n",
    "\n",
    " </td><td>\n",
    "\n",
    " <img src='https://scikit-learn.org/stable/_images/sphx_glr_plot_confusion_matrix_002.png  ' style='width: 400px;'></td></tr></table>\n",
    "\n",
    " <br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " ### Задание:\n",
    "\n",
    " 1. Реализовать метод матрицы ошибок с нуля с использованием списков python и numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_confusion_matrix(true_labels, pred_labels):\n",
    "    \"\"\"Вычислить матрицу ошибок для оценки точности классификации\n",
    "\n",
    "    Параметры\n",
    "    ----------\n",
    "    true_labels : array-like формы (n_samples,)\n",
    "        Истинные (правильные) целевые значения.\n",
    "    pred_labels : array-like формы (n_samples,)\n",
    "        Оцененные цели, возвращенные классификатором.\n",
    "    \"\"\"\n",
    "    # TODO : Реализовать\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## вычисление матрицы ошибок\n",
    "y_true = [2, 0, 2, 2, 0, 1]\n",
    "y_pred = [0, 0, 2, 2, 0, 2]\n",
    "print(\"Матрица ошибок для теста 1\")\n",
    "print(calc_confusion_matrix(y_true, y_pred))\n",
    "\n",
    "titanic_cm = calc_confusion_matrix(y_test, clf.predict(x_test))\n",
    "print(\"Матрица ошибок для Титаника:\\n\", titanic_cm, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запустите этот блок кода, чтобы увидеть, как должен выглядеть ваш результат\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\n",
    "    \"sklearn Матрица ошибок для тестового набора:\\n\",\n",
    "    confusion_matrix(y_true, y_pred),\n",
    ")\n",
    "print(\n",
    "    \"sklearn Матрица ошибок для Титаника:\\n\",\n",
    "    confusion_matrix(y_test, clf.predict(x_test)),\n",
    "    \"\\n\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 5. Регуляризация: Lasso и Ridge\n",
    "\n",
    " Обе модели являются регуляризованными формами линейной регрессии.\n",
    "\n",
    " Lasso (L1-регуляризация) может обнулять коэффициенты, тем самым выполняя отбор признаков.\n",
    "\n",
    " Ridge (L2-регуляризация) уменьшает величину коэффициентов, но не обнуляет их.\n",
    "\n",
    " Подробнее: [User Guide: Linear Models](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification)\n",
    "\n",
    " ### Проблемы:\n",
    "\n",
    " 1. Когда использовать Lasso?\n",
    "\n",
    "\n",
    "\n",
    " 2. Когда использовать Ridge?\n",
    "\n",
    "\n",
    "\n",
    " 3. Так как трудно определить влияние параметров, как мы можем решить, какую регуляризацию использовать? и определить значение lambda (alpha в sklearn)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 5.1 Загрузка датасета Boston\n",
    "\n",
    " Значения цен на жилье в пригородах Бостона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем альтернативную функцию для загрузки датасета Boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_boston():\n",
    "    header = [\n",
    "        \"CRIM\",\n",
    "        \"ZN\",\n",
    "        \"INDUS\",\n",
    "        \"CHAS\",\n",
    "        \"NOX\",\n",
    "        \"RM\",\n",
    "        \"AGE\",\n",
    "        \"DIS\",\n",
    "        \"RAD\",\n",
    "        \"TAX\",\n",
    "        \"PTRATIO\",\n",
    "        \"B\",\n",
    "        \"LSTAT\",\n",
    "        \"MEDV\",\n",
    "    ]\n",
    "    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "    raw_df = pd.read_csv(data_url, sep=\"\\\\s+\", skiprows=22, header=None)\n",
    "    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "    target = np.expand_dims(raw_df.values[1::2, 2], 1)\n",
    "    df = pd.DataFrame(np.hstack([data, target]), columns=header)\n",
    "    return df\n",
    "\n",
    "\n",
    "boston_df = load_boston()\n",
    "X = boston_df.drop(\"MEDV\", axis=1).values\n",
    "y = boston_df[\"MEDV\"].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123\n",
    ")\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=1 / 8, random_state=123\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 5.2 Обучение моделей Lasso и Ridge\n",
    "\n",
    " Подробнее о Lasso: [sklearn.linear_model.Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "\n",
    " Подробнее о Ridge: [sklearn.linear_model.Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "\n",
    "\n",
    "\n",
    " ### Задание:\n",
    "\n",
    " 1. Обучить две модели: Lasso и Ridge - со значением alpha по умолчанию.\n",
    "\n",
    " 2. Затем вывести их коэффициенты и обратить внимание на разницу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "lasso = None  # TODO: инициализировать Lasso\n",
    "ridge = None  # TODO: инициализировать Ridge\n",
    "lasso.fit(x_train, y_train)\n",
    "ridge.fit(x_train, y_train)\n",
    "\n",
    "# TODO: вывести коэффициенты моделей\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Задание:\n",
    "\n",
    " 1. Давайте попробуем разные значения для alpha для регрессора Lasso и построим график потерь на валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline\n",
    "\n",
    "alphas = [2.2, 2, 1.5, 1.3, 1.2, 1.1, 1, 0.3, 0.1]\n",
    "losses = []\n",
    "for alpha in alphas:\n",
    "    # TODO:\n",
    "    # Написать (5 строк): создать регрессор Lasso с указанным значением alpha.\n",
    "    # Обучить его на обучающей выборке, затем получить предсказание на валидационной выборке (x_val).\n",
    "    # вычислить среднеквадратичную ошибку, затем добавить её в массив losses\n",
    "\n",
    "plt.plot(alphas, losses)\n",
    "plt.title(\"Выбор значения alpha для Lasso\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"Среднеквадратичная ошибка\")\n",
    "plt.show()\n",
    "\n",
    "best_alpha = alphas[np.argmin(losses)]\n",
    "print(\"Лучшее значение alpha:\", best_alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Измерение потерь на тестовом наборе с регрессором Lasso с лучшим alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(best_alpha)\n",
    "lasso.fit(x_train, y_train)\n",
    "y_pred = lasso.predict(x_test)\n",
    "print(\n",
    "    \"Среднеквадратичная ошибка на тестовом наборе:\",\n",
    "    mean_squared_error(y_test, y_pred),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 6. Наивный Байес\n",
    "\n",
    " Мы будем использовать гауссовский наивный Байес (`GaussianNB`), который, исходя из предположения, работает с непрерывными признаками как с гауссовыми переменными для вычисления их вероятности.\n",
    "\n",
    " $$P(x_i|y) = \\frac{1}{\\sqrt{2\\pi\\sigma_y^2}}exp(-\\frac{(x_i - \\mu_y)^2}{2\\sigma_y^2})$$\n",
    "\n",
    " Где $\\mu_y$ и $\\sigma_y^2$ - среднее и дисперсия признака $i$ для класса $y$.\n",
    "\n",
    " Подробнее: [User Guide: Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "\n",
    " Примечание: Различные классификаторы наивного Байеса в основном различаются предположениями, которые они делают относительно распределения $P(x_i|y)$.\n",
    "\n",
    " ___\n",
    "\n",
    " Каковы плюсы и минусы классификатора наивного Байеса?\n",
    "\n",
    "\n",
    "\n",
    " ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 6.1 Загрузка датасета\n",
    "\n",
    " Датасет из 10 классов цифр, состоящий из изображений 8x8 пикселей. Подходит для задачи классификации!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# Мы покажем, почему не разделили валидационный набор.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 6.2 Построение, обучение и тестирование модели\n",
    "\n",
    " Подробнее о GaussianNB: [sklearn.naive_bayes.GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "\n",
    " Давайте обучим модель наивного Байеса и проверим точность на тестовом наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gauss_nb = GaussianNB()\n",
    "gauss_nb.fit(x_train, y_train)\n",
    "y_pred = gauss_nb.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Задание : Вычислить простую матрицу ошибок и нормализованную матрицу ошибок для оценки производительности модели\n",
    "\n",
    " **Примечание:** См. [`sklearn.metrics.plot_confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html) (функция `plot_confusion_matrix` устарела, используйте `ConfusionMatrixDisplay.from_estimator`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: простая матрица ошибок\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Используйте ConfusionMatrixDisplay.from_estimator(clf, x_test, y_test) для простой матрицы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: нормализованная матрица ошибок\n",
    "# Используйте normalize='true' в from_estimator или from_predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 7. Классификатор k-ближайших соседей (KNN)\n",
    "\n",
    " KNN - это непараметрический метод, основанный на схожести. Прогноз делается на основе k ближайших соседей.\n",
    "\n",
    " Подробнее: [User Guide: Nearest Neighbors](https://scikit-learn.org/stable/modules/neighbors.html)\n",
    "\n",
    " 1. Каковы плюсы и минусы KNN?\n",
    "\n",
    "\n",
    "\n",
    "     <span style=\"color:blue\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " 2. Чтобы увеличить дисперсию модели KNN, нужно увеличить или уменьшить K?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 7.1 Загрузка и предварительная обработка данных\n",
    "\n",
    " Подробнее о StandardScaler: [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "\n",
    " Давайте сделаем то же самое с классификатором KNN.\n",
    "\n",
    " Почему нужно масштабировать признаки? KNN чувствителен к масштабу признаков, так как использует расстояния."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Как выбрать оптимальный $k$ ?\n",
    "\n",
    " Давайте настроим гиперпараметр $n\\_neighbors$ в объекте классификатора KNN, используя кросс-валидацию.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 8. Кросс-валидация\n",
    "\n",
    " Кросс-валидация приходит как альтернатива разделению на валидационный набор.\n",
    "\n",
    " Подробнее: [User Guide: Cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    " Примечание: поэтому мы не создавали валидационный набор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "Ks = list(range(1, 20))\n",
    "cv_scores = []\n",
    "for K in Ks:\n",
    "    knn = KNeighborsClassifier(n_neighbors=K)\n",
    "    scores = cross_val_score(knn, x_train, y_train, cv=7, scoring=\"accuracy\")\n",
    "    avg_score = np.mean(scores)\n",
    "    cv_scores.append(avg_score)\n",
    "\n",
    "plt.plot(Ks, cv_scores)\n",
    "plt.show()\n",
    "print(cv_scores)\n",
    "print(Ks[np.argmax(cv_scores)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " В классификаторе KNN есть несколько гиперпараметров для настройки, настройка их по одному - это трудоемкий подход.\n",
    "\n",
    " Давайте попробуем лучший подход, называемый GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 9. Подбор гиперпараметров\n",
    "\n",
    " Подбор гиперпараметров - это процесс выбора набора оптимальных гиперпараметров для алгоритма машинного обучения.\n",
    "\n",
    " Подробнее: [User Guide: Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html)\n",
    "\n",
    " Стратегии настройки:\n",
    "\n",
    " 1. Поиск по сетке (Grid Search): перебор всех комбинаций. Подробнее: [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    " 1. Случайный поиск (Random Search): случайный выбор параметров из заданного пространства поиска. Подробнее: [sklearn.model_selection.RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "\n",
    "\n",
    "\n",
    " Задание:\n",
    "\n",
    " Использовать gridsearch для настройки 3 гиперпараметров:\n",
    "\n",
    "\n",
    "\n",
    " 1. $n\\_neighbors$: `[1, 2, . . ., 10]`\n",
    "\n",
    " 2. $weights$: `['uniform', 'distance']`\n",
    "\n",
    " 3. $metric$: `['euclidean', 'manhattan', 'chebyshev', 'cosine']`\n",
    "\n",
    "\n",
    "\n",
    " См. этот [ссылка](https://scikit-learn.org/stable/modules/grid_search.html) для справки.\n",
    "\n",
    "\n",
    "\n",
    " Затем измерить точность на тестовом наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": list(range(1, 11)),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"chebyshev\", \"cosine\"],\n",
    "}\n",
    "\n",
    "grid_search_clf = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    cv=7,\n",
    "    scoring=\"accuracy\",\n",
    "    param_grid=param_grid,\n",
    ")\n",
    "\n",
    "grid_search_clf.fit(x_train, y_train)\n",
    "means = grid_search_clf.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_search_clf.cv_results_[\"std_test_score\"]\n",
    "for mean, std, params in zip(\n",
    "    means, stds, grid_search_clf.cv_results_[\"params\"]\n",
    "):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "print(\"Найденный набор лучших параметров:\")\n",
    "print()\n",
    "print(grid_search_clf.best_params_)\n",
    "\n",
    "y_pred = grid_search_clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 9.1 Задание :\n",
    "\n",
    " Использовать случайный поиск для настройки 3 гиперпараметров:\n",
    "\n",
    "\n",
    "\n",
    " 1. $n\\_neighbors$: `[1, 2, . . ., 10]`\n",
    "\n",
    " 2. $weights$: `['uniform', 'distance']`\n",
    "\n",
    " 3. $metric$: `['euclidean', 'manhattan', 'chebyshev', 'cosine']`\n",
    "\n",
    "\n",
    "\n",
    " См. этот [ссылка](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) для справки.\n",
    "\n",
    "\n",
    "\n",
    " Затем измерить точность на тестовом наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Измените следующие строки, чтобы запустить RandomizedSearchCV с cv=5\n",
    "param_grid = {\n",
    "    \"n_neighbors\": list(range(1, 11)),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"chebyshev\", \"cosine\"],\n",
    "}  # TODO : Определить пространство поиска гиперпараметров\n",
    "\n",
    "randomized_search_clf = RandomizedSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    random_state=42,\n",
    ")  # TODO : Определить класс случайного поиска из sklearn\n",
    "randomized_search_clf.fit(\n",
    "    x_train, y_train\n",
    ")  # random заменен на randomized_search_clf\n",
    "\n",
    "print(\"Лучший результат: \", randomized_search_clf.best_score_)\n",
    "print(\"Лучшие параметры: \", randomized_search_clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = randomized_search_clf.predict(x_test)\n",
    "print(f\"Тест на тестовом наборе : {accuracy_score(y_test, y_pred):.4}\")\n",
    "\n",
    "# TODO: Добавьте сравнение результатов GridSearch и RandomizedSearch\n",
    "\n",
    "# TODO: Добавьте HalvingGridSearchCV или HalvingRandomSearchCV для сравнения скорости и качества\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
